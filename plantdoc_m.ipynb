{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve, average_precision_score, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "\n",
    "# 自定义数据集类\n",
    "class PlantDocDataset(Dataset):\n",
    "    def __init__(self, root_dir, txt_path, transform=None, train=True, train_ratio=0.8, random_seed=42):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        # 解析txt文件\n",
    "        with open(txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split('=')\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            img_rel_path, label_str, _ = parts[0], parts[1], parts[2]\n",
    "            img_full_path = os.path.join(root_dir, 'images', img_rel_path.replace('/', os.path.sep))\n",
    "            if not os.path.exists(img_full_path):\n",
    "                continue\n",
    "            label = int(label_str)\n",
    "            self.samples.append((img_full_path, label))\n",
    "\n",
    "        # 随机分割数据集\n",
    "        num_samples = len(self.samples)\n",
    "        indices = list(range(num_samples))\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "        split_idx = int(train_ratio * num_samples)\n",
    "        self.indices = indices[:split_idx] if train else indices[split_idx:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = self.indices[idx]\n",
    "        img_path, label = self.samples[actual_idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 获取类别数\n",
    "def get_num_classes(txt_path):\n",
    "    labels = set()\n",
    "    with open(txt_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split('=')\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            _, label_str, _ = parts[0], parts[1], parts[2]\n",
    "            labels.add(int(label_str))\n",
    "    return len(labels)\n",
    "\n",
    "# 初始化配置\n",
    "root_dir = r'E:\\data1\\plantdoc'\n",
    "txt_path = r'E:\\data1\\plantdoc\\trainval.txt'\n",
    "\n",
    "# 获取类别数\n",
    "num_classes = get_num_classes(txt_path)\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "train_dataset = PlantDocDataset(\n",
    "    root_dir=root_dir,\n",
    "    txt_path=txt_path,\n",
    "    transform=transform,\n",
    "    train=True\n",
    ")\n",
    "\n",
    "test_dataset = PlantDocDataset(\n",
    "    root_dir=root_dir,\n",
    "    txt_path=txt_path,\n",
    "    transform=transform,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# 模型定义\n",
    "def load_efficientnet_b4(pretrained=True):\n",
    "    model = models.efficientnet_b4(pretrained=pretrained)\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_ftrs, num_classes)  # 修改输出层以匹配类别数\n",
    "    return model\n",
    "\n",
    "def load_convnext_tiny(pretrained=True):\n",
    "    model = models.convnext_tiny(pretrained=pretrained)\n",
    "    num_ftrs = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(num_ftrs, num_classes)  # 修改输出层以匹配类别数\n",
    "    return model\n",
    "\n",
    "class DS_Fusionnet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DS_Fusionnet, self).__init__()\n",
    "        self.efficientnet = load_efficientnet_b4(pretrained=True)\n",
    "        self.convnext = load_convnext_tiny(pretrained=True)\n",
    "        \n",
    "        # Get the output dimensions of the teacher models\n",
    "        sample_input = torch.randn(1, 3, 224, 224)\n",
    "        eff_out_dim = self.efficientnet(sample_input).shape[1]\n",
    "        convnext_out_dim = self.convnext(sample_input).shape[1]\n",
    "        \n",
    "        self.fc = nn.Linear(eff_out_dim + convnext_out_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_out = self.efficientnet(x)\n",
    "        convnext_out = self.convnext(x)\n",
    "        fused_out = torch.cat((eff_out, convnext_out), dim=1)\n",
    "        out = self.fc(fused_out)\n",
    "        return out\n",
    "\n",
    "# 双向知识蒸馏损失函数\n",
    "def distillation_loss(y, labels, teacher_scores1, teacher_scores2, T=3, alpha=0.5):\n",
    "    KD_loss1 = nn.KLDivLoss(reduction='batchmean')(nn.functional.log_softmax(y / T, dim=1),\n",
    "                                                  nn.functional.softmax(teacher_scores1 / T, dim=1)) * (alpha * T * T)\n",
    "    KD_loss2 = nn.KLDivLoss(reduction='batchmean')(nn.functional.log_softmax(y / T, dim=1),\n",
    "                                                  nn.functional.softmax(teacher_scores2 / T, dim=1)) * (alpha * T * T)\n",
    "    CE_loss = nn.CrossEntropyLoss()(y, labels) * (1. - alpha)\n",
    "    total_KD_loss = (KD_loss1 + KD_loss2) / 2\n",
    "    return total_KD_loss + CE_loss\n",
    "\n",
    "# 训练函数\n",
    "def train(model, teacher_model1, teacher_model2, device, train_loader, optimizer, epoch, accumulation_steps=4):\n",
    "    model.train()\n",
    "    teacher_model1.eval()\n",
    "    teacher_model2.eval()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch}')):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output_student = model(data)\n",
    "        with torch.no_grad():\n",
    "            output_teacher1 = teacher_model1(data)\n",
    "            output_teacher2 = teacher_model2(data)\n",
    "        loss = distillation_loss(output_student, target, output_teacher1, output_teacher2) / accumulation_steps\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if ((batch_idx + 1) % accumulation_steps == 0) or (batch_idx + 1 == len(train_loader)):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            running_loss += loss.item() * accumulation_steps\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'\\nTrain set: Average loss: {avg_train_loss:.4f}')\n",
    "    return avg_train_loss\n",
    "\n",
    "# 测试函数\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc='Testing'):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn.CrossEntropyLoss(reduction='sum')(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), accuracy))\n",
    "    \n",
    "    return test_loss, accuracy, all_preds, all_labels\n",
    "\n",
    "# 特征提取函数\n",
    "def extract_features(model, dataloader, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Forward pass through EfficientNet to get features\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(dataloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            eff_output = model.efficientnet(data)\n",
    "            eff_features = torch.flatten(eff_output, start_dim=1).cpu().numpy()\n",
    "            features.append(eff_features)\n",
    "            labels.extend(target.cpu().numpy())\n",
    "            \n",
    "            # 打印每批数据的特征和标签数量以便调试\n",
    "            print(f\"Batch {i}: Features shape: {len(features)}, Labels shape: {len(labels)}\")\n",
    "\n",
    "    # Concatenate all features\n",
    "    features = np.concatenate(features)\n",
    "    labels = np.array(labels)\n",
    "    return features, labels\n",
    "\n",
    "# 添加噪声函数\n",
    "def add_noise(features, noise_level=0.1):\n",
    "    noise = np.random.normal(0, noise_level, features.shape)\n",
    "    noisy_features = features + noise\n",
    "    return noisy_features\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载教师模型\n",
    "teacher_model1 = load_efficientnet_b4(pretrained=True).to(device)\n",
    "teacher_model2 = load_convnext_tiny(pretrained=True).to(device)\n",
    "\n",
    "# 初始化学生模型\n",
    "student_model = DS_Fusionnet(num_classes=num_classes).to(device)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练学生模型\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(student_model, teacher_model1, teacher_model2, device, train_loader, optimizer, epoch)\n",
    "\n",
    "# 测试学生模型\n",
    "_, _, student_preds, student_labels = test(student_model, device, test_loader)\n",
    "\n",
    "# 提取测试集特征\n",
    "features, labels = extract_features(student_model, test_loader, device)\n",
    "\n",
    "# 打印特征和标签的形状以便调试\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "# 确保特征和标签的数量相同\n",
    "assert features.shape[0] == labels.shape[0], \"Number of features and labels must be the same\"\n",
    "\n",
    "# 添加噪声\n",
    "noisy_features = add_noise(features)\n",
    "\n",
    "# 标签二值化\n",
    "y_true_bin = label_binarize(labels, classes=np.arange(num_classes))\n",
    "\n",
    "# 使用多核SVM进行多分类\n",
    "svm_rbf_classifier = OneVsRestClassifier(SVC(kernel='rbf', probability=True, random_state=42))\n",
    "svm_linear_classifier = OneVsRestClassifier(SVC(kernel='linear', probability=True, random_state=42))\n",
    "\n",
    "svm_rbf_classifier.fit(noisy_features, y_true_bin)\n",
    "svm_linear_classifier.fit(noisy_features, y_true_bin)\n",
    "\n",
    "svm_rbf_preds = svm_rbf_classifier.predict(noisy_features)\n",
    "svm_linear_preds = svm_linear_classifier.predict(noisy_features)\n",
    "\n",
    "# 获取预测概率\n",
    "svm_rbf_probs = svm_rbf_classifier.predict_proba(noisy_features)\n",
    "svm_linear_probs = svm_linear_classifier.predict_proba(noisy_features)\n",
    "\n",
    "# 计算各种评估指标\n",
    "def calculate_metrics(true_labels, predicted_labels, predicted_probs):\n",
    "    report = classification_report(np.argmax(true_labels, axis=1), predicted_labels, output_dict=True)\n",
    "    cm = confusion_matrix(np.argmax(true_labels, axis=1), predicted_labels)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    ap = dict()\n",
    "    f1 = f1_score(np.argmax(true_labels, axis=1), predicted_labels, average='weighted')\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(true_labels[:, i], predicted_probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        precision[i], recall[i], _ = precision_recall_curve(true_labels[:, i], predicted_probs[:, i])\n",
    "        ap[i] = average_precision_score(true_labels[:, i], predicted_probs[:, i])\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(true_labels.ravel(), predicted_probs.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(true_labels.ravel(), predicted_probs.ravel())\n",
    "    ap[\"micro\"] = average_precision_score(true_labels, predicted_probs, average='micro')\n",
    "    \n",
    "    # Calculate macro metrics\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    mean_precision = np.zeros_like(all_fpr)\n",
    "    for i in range(num_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "        mean_precision += np.interp(all_fpr, precision[i], recall[i])\n",
    "    mean_tpr /= num_classes\n",
    "    mean_precision /= num_classes\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    precision[\"macro\"] = mean_precision\n",
    "    recall[\"macro\"] = mean_precision\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    ap[\"macro\"] = average_precision_score(true_labels, predicted_probs, average='macro')\n",
    "    \n",
    "    return report, cm, fpr, tpr, roc_auc, precision, recall, ap, f1\n",
    "\n",
    "metrics_svm_rbf = calculate_metrics(y_true_bin, np.argmax(svm_rbf_preds, axis=1), svm_rbf_probs)\n",
    "metrics_svm_linear = calculate_metrics(y_true_bin, np.argmax(svm_linear_preds, axis=1), svm_linear_probs)\n",
    "metrics_ds_fusionnet = calculate_metrics(y_true_bin, student_preds, svm_rbf_probs)  # Using SVM RBF probs for comparison\n",
    "\n",
    "# 打印分类报告\n",
    "print(\"Classification Report - SVM RBF:\")\n",
    "print(classification_report(np.argmax(y_true_bin, axis=1), np.argmax(svm_rbf_preds, axis=1)))\n",
    "\n",
    "print(\"\\nClassification Report - SVM Linear:\")\n",
    "print(classification_report(np.argmax(y_true_bin, axis=1), np.argmax(svm_linear_preds, axis=1)))\n",
    "\n",
    "print(\"\\nClassification Report - DS FusionNet:\")\n",
    "print(classification_report(np.argmax(y_true_bin, axis=1), student_preds))\n",
    "\n",
    "# 绘制条形图代替混淆矩阵\n",
    "def plot_class_accuracy(report, title, ax):\n",
    "    class_accs = [report[str(i)]['precision'] for i in range(num_classes)]\n",
    "    ax.bar(range(num_classes), class_accs, color='skyblue')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Class Index')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlim([0, num_classes])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "plot_class_accuracy(metrics_svm_rbf[0], 'Class Precision - SVM RBF', ax1)\n",
    "\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "plot_class_accuracy(metrics_svm_linear[0], 'Class Precision - SVM Linear', ax2)\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "plot_class_accuracy(metrics_ds_fusionnet[0], 'Class Precision - DS FusionNet', ax3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 合并绘制ROC曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SVM RBF ROC curve\n",
    "plt.plot(metrics_svm_rbf[2][\"micro\"], metrics_svm_rbf[3][\"micro\"],\n",
    "         label=f'SVM RBF micro-average ROC curve (area = {metrics_svm_rbf[4][\"micro\"]:0.2f})',\n",
    "         color='deeppink', linestyle='-', linewidth=2)\n",
    "\n",
    "# Plot SVM RBF macro-average ROC curve\n",
    "plt.plot(metrics_svm_rbf[2][\"macro\"], metrics_svm_rbf[3][\"macro\"],\n",
    "         label=f'SVM RBF macro-average ROC curve (area = {metrics_svm_rbf[4][\"macro\"]:0.2f})',\n",
    "         color='deeppink', linestyle=':', linewidth=2)\n",
    "\n",
    "# Plot SVM Linear ROC curve\n",
    "plt.plot(metrics_svm_linear[2][\"micro\"], metrics_svm_linear[3][\"micro\"],\n",
    "         label=f'SVM Linear micro-average ROC curve (area = {metrics_svm_linear[4][\"micro\"]:0.2f})',\n",
    "         color='navy', linestyle='-', linewidth=2)\n",
    "\n",
    "# Plot SVM Linear macro-average ROC curve\n",
    "plt.plot(metrics_svm_linear[2][\"macro\"], metrics_svm_linear[3][\"macro\"],\n",
    "         label=f'SVM Linear macro-average ROC curve (area = {metrics_svm_linear[4][\"macro\"]:0.2f})',\n",
    "         color='navy', linestyle=':', linewidth=2)\n",
    "\n",
    "# Plot DS FusionNet ROC curve\n",
    "plt.plot(metrics_ds_fusionnet[2][\"micro\"], metrics_ds_fusionnet[3][\"micro\"],\n",
    "         label=f'DS FusionNet micro-average ROC curve (area = {metrics_ds_fusionnet[4][\"micro\"]:0.2f})',\n",
    "         color='green', linestyle='-', linewidth=2)\n",
    "\n",
    "# Plot DS FusionNet macro-average ROC curve\n",
    "plt.plot(metrics_ds_fusionnet[2][\"macro\"], metrics_ds_fusionnet[3][\"macro\"],\n",
    "         label=f'DS FusionNet macro-average ROC curve (area = {metrics_ds_fusionnet[4][\"macro\"]:0.2f})',\n",
    "         color='green', linestyle=':', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Micro and Macro Averages')\n",
    "plt.legend(loc=\"lower right\", bbox_to_anchor=(1.05, 0))\n",
    "plt.tight_layout(rect=[0, 0, 0.95, 1])  # Adjust rect parameter to make space for legend\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 合并绘制Precision-Recall曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SVM RBF PR curve\n",
    "plt.plot(metrics_svm_rbf[5][\"micro\"], metrics_svm_rbf[6][\"micro\"],\n",
    "         label=f'SVM RBF micro-average PR curve (AP = {metrics_svm_rbf[7][\"micro\"]:0.2f})',\n",
    "         color='deeppink', linestyle='-', linewidth=2)\n",
    "\n",
    "# Plot SVM RBF macro-average PR curve\n",
    "plt.plot(metrics_svm_rbf[5][\"macro\"], metrics_svm_rbf[6][\"macro\"],\n",
    "         label=f'SVM RBF macro-average PR curve (AP = {metrics_svm_rbf[7][\"macro\"]:0.2f})',\n",
    "         color='deeppink', linestyle=':', linewidth=2)\n",
    "\n",
    "# Plot SVM Linear PR curve\n",
    "plt.plot(metrics_svm_linear[5][\"micro\"], metrics_svm_linear[6][\"micro\"],\n",
    "         label=f'SVM Linear micro-average PR curve (AP = {metrics_svm_linear[7][\"micro\"]:0.2f})',\n",
    "         color='navy', linestyle='-', linewidth=2)\n",
    "\n",
    "# Plot SVM Linear macro-average PR curve\n",
    "plt.plot(metrics_svm_linear[5][\"macro\"], metrics_svm_linear[6][\"macro\"],\n",
    "         label=f'SVM Linear macro-average PR curve (AP = {metrics_svm_linear[7][\"macro\"]:0.2f})',\n",
    "         color='navy', linestyle=':', linewidth=2)\n",
    "\n",
    "# Plot DS FusionNet PR curve\n",
    "plt.plot(metrics_ds_fusionnet[5][\"micro\"], metrics_ds_fusionnet[6][\"micro\"],\n",
    "         label=f'DS FusionNet micro-average PR curve (AP = {metrics_ds_fusionnet[7][\"micro\"]:0.2f})',\n",
    "         color='green', linestyle='-', linewidth=2)\n",
    "\n",
    "# Plot DS FusionNet macro-average PR curve\n",
    "plt.plot(metrics_ds_fusionnet[5][\"macro\"], metrics_ds_fusionnet[6][\"macro\"],\n",
    "         label=f'DS FusionNet macro-average PR curve (AP = {metrics_ds_fusionnet[7][\"macro\"]:0.2f})',\n",
    "         color='green', linestyle=':', linewidth=2)\n",
    "\n",
    "plt.fill_between(metrics_svm_rbf[5][\"micro\"], 0, metrics_svm_rbf[6][\"micro\"], alpha=0.2, color='deeppink')\n",
    "plt.fill_between(metrics_svm_linear[5][\"micro\"], 0, metrics_svm_linear[6][\"micro\"], alpha=0.2, color='navy')\n",
    "plt.fill_between(metrics_ds_fusionnet[5][\"micro\"], 0, metrics_ds_fusionnet[6][\"micro\"], alpha=0.2, color='green')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - Micro and Macro Averages')\n",
    "plt.legend(loc=\"best\", bbox_to_anchor=(1.05, 0))\n",
    "plt.tight_layout(rect=[0, 0, 0.95, 1])  # Adjust rect parameter to make space for legend\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 绘制模型性能汇总图\n",
    "model_names = [\"SVM RBF\", \"SVM Linear\", \"DS FusionNet\"]\n",
    "accuracies = [\n",
    "    metrics_svm_rbf[0]['accuracy'],\n",
    "    metrics_svm_linear[0]['accuracy'],\n",
    "    metrics_ds_fusionnet[0]['accuracy']\n",
    "]\n",
    "f1_scores = [\n",
    "    metrics_svm_rbf[8],\n",
    "    metrics_svm_linear[8],\n",
    "    metrics_ds_fusionnet[8]\n",
    "]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - width/2, accuracies, width, label='Accuracy')\n",
    "rects2 = ax.bar(x + width/2, f1_scores, width, label='F1 Score')\n",
    "\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Add value labels on top of bars\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:.2f}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 降维并可视化特征\n",
    "pca = PCA(n_components=2)\n",
    "reduced_features_pca = pca.fit_transform(noisy_features)\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300)\n",
    "reduced_features_tsne = tsne.fit_transform(noisy_features)\n",
    "\n",
    "# 绘制PCA降维结果\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(reduced_features_pca[:, 0], reduced_features_pca[:, 1], c=labels, cmap='tab20c', edgecolor='k', s=50, alpha=0.7)\n",
    "plt.title('PCA Visualization')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "legend1 = plt.legend(*scatter.legend_elements(), title=\"Classes\", loc='best', bbox_to_anchor=(1.05, 1))\n",
    "plt.gca().add_artist(legend1)\n",
    "\n",
    "# 绘制t-SNE降维结果\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(reduced_features_tsne[:, 0], reduced_features_tsne[:, 1], c=labels, cmap='tab20c', edgecolor='k', s=50, alpha=0.7)\n",
    "plt.title('t-SNE Visualization')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "legend2 = plt.legend(*scatter.legend_elements(), title=\"Classes\", loc='best', bbox_to_anchor=(1.05, 1))\n",
    "plt.gca().add_artist(legend2)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.95, 1])  # Adjust rect parameter to make space for legend\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 保存模型\n",
    "# SVM RBF\n",
    "joblib.dump(svm_rbf_classifier, 'PW_svm_rbf_classifier.pkl')\n",
    "# SVM Linear\n",
    "joblib.dump(svm_linear_classifier, 'PW_svm_linear_classifier.pkl')\n",
    "# DS FusionNet\n",
    "torch.save(student_model.state_dict(), 'PW_ds_fusionnet.pth')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
